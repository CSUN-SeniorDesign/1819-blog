---
title: "Hat-Hayden-Week-22"
author: Hayden
date: 2019-03-08T18:31:27-08:00
tags: ["Hayden Wilcox", "HAT", "Week 22"]
draft: false
---

This week, I was assigned to set up a monitoring system for our project. I decided to choose Datadog, as it seemed like the simplest to set up, and also the cheapest. I began with the goal of setting up the Datadog using Docker. The idea was to utilize a multistage build with our wordpress Dockerfile, to set up the image with the monitoring system pre-installed. I struggled with this, due to my lack of understanding of Docker and conflicting documentation. Often times, the documentation would tell you to install the system with a command, but then talk about the "customizability" of Datadog, with seemingly no way to configure it with the command alone. I was also trying get the Datadog container to monitor the host environment around it, which wasn't working as it is specifically geared to monitor its container. Meaning that downloading the container via a command would simply make a Datadog container that monitored itself, which wasn't very useful to our project. It did however, let me set up a dashboard to monitor the container, though activity was fairly lacking for obvious reasons. Eventually, I began looking for a premade Dockerfile to copy, but unfortunately couldn't find one that would work without significant modification. I realized that my lack of understanding of how to actually construct a Dockerfile would impede my progress in this, and I began to look into how to make one.

At this point, Aubrey linked me an article that showed a method for setting up a Datadog task that would run on an ECS cluster like our system. The idea is that each EC2 instance in the cluster would have its own Datadog container that would monitor both the instance it's in and every other instance in the cluster, then send all these metrics to Datadog HQ for collection.

The 1st step involved setting up an ECS task definition using the AWS CLI and a .json which came from the site. The .json file contained information that would set up monitoring containers enabled for ECS.

The 2nd step was to configure the IAM policy to allow for logs to be collected between the instances, and then be sent out to Datadog HQ to be viewed on the dashboard. This required going through the manual setup on AWS itself.

The final step was to set up a daemon that would make the containers on the instances monitor their instances and each other, and to send the metrics to DD HQ. This was also done manually through the AWS dashboard.

The final product worked well and was able to send and receive metrics from the containers and monitor network traffic across the cluster. The only drawback was the amount of manual work it took on my end to set everything up. This is when Tyler stepped in and took what I did and turned it into a series of terraform modules that could be run and automatically set up when the terraform was run. This took the manual work out of the picture and got the same result working with automation, a step I hadn't thought of.

On a personal note, due to my amount of free time after this, I worked on my understanding of Docker and was finally able to write my own Dockerfile and image. This was spurned by the necessity of always setting up a container when doing in class assignments and wanted a way to set it up automatically. Which is exactly what Dockerfiles were designed to do. I also troubleshooted a few connection issues involving connectivity with my Docker containers. Namely, whenever my laptop was closed, they could no longer connect to the internet. This was due to the containers losing connection to the VM they ran on in my Oracle VirtualBox software and could be rectified by closing the VM and restarting Docker. I also experienced an issue when Ansible locked up during setting up a LAMP-stack. The issue was that if the laptop closed or went off for any reason during installation, it would create a lock file that wouldn't be deleted, causing all further attempts at using the apt function to cause an error. This was fixed by deleting all lock files and doing apt-get upgrade to reset the system and allow the apt process to be utilized again. This is an issue that affected me last year and was never resolved, and part of why I initially disliked Ansible despite its practical uses. This of course, made me very happy as I could finally take advantage of Ansible after almost a year without worrying about the lockup issue.